{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Image Registration\n",
    "\n",
    "You will find the entire lab manual in this file. Some exercises require you to write a text answer, others require you to write code. You should not define functions inside this file. Instead save functions to a functions file (`functions.py`) and call them from the code cells in this notebook.\n",
    "\n",
    "## Submission Requirements:\n",
    "Your final lab submission should include:\n",
    "\n",
    "- Your edited **notebook file** (`.ipynb`).\n",
    "- Your **`functions.py`** file containing all function definitions.\n",
    "- A **HTML printout** of the executed notebook with all outputs visible: File → Save and export Notebook As → HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this lab is to learn how to register two images using an affine transformation. An affine transformation is written as:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{l}\n",
    "\\tilde{x} \\\\\n",
    "\\tilde{y}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{ll}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "x \\\\\n",
    "y\n",
    "\\end{array}\\right)+\\left(\\begin{array}{l}\n",
    "t_{x} \\\\\n",
    "t_{y}\n",
    "\\end{array}\\right)=A\\left(\\begin{array}{l}\n",
    "x \\\\\n",
    "y\n",
    "\\end{array}\\right)+t\n",
    "$$\n",
    "\n",
    "It can also be written using homogeneous coordinates as:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{l}\n",
    "\\tilde{x} \\\\\n",
    "\\tilde{y} \\\\\n",
    "1\n",
    "\\end{array}\\right)=\\left(\\begin{array}{ll}\n",
    "a & b & t_{x}\\\\\n",
    "c & d & t_{y}\\\\\n",
    "0 & 0 & 1\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{array}\\right)=T\\left(\\begin{array}{l}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "where $T$ is an affine transformation matrix. Apart from rotation, translation and scaling, it also allows strecthing the image in an arbitrary dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "What is the minimal number of point correspondences, $K$, required in order to estimate an affine transformation between two images?\n",
    "\n",
    "In general, an estimation problem where the minimal of amount of measurements is used to estimate the unknown parameters is called a minimal problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "Once you have found a proper coordinate transformation between two images, you can use the provided function `affine_warp` to warp the source image and create a warped image. Let’s try it.\n",
    "\n",
    "Load the image `mona.png` to the variable `img`. After copying your `read_image` function from previous labs into the functions directory, try running the following code snippet. Play around with the values in A, t to see the results and understand the effect of how to rotate, translate and stretch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplied import affine_warp, read_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = read_image('./data/mona.png'); \n",
    "\n",
    "# Square transformation matrix\n",
    "T = np.array([[0.88, -0.48, 100],\n",
    "              [0.48, 0.88, -100],\n",
    "              [0, 0, 1]])\n",
    "\n",
    "\n",
    "warped = affine_warp(img, T, img.shape)\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(warped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values in $A$ and $t$ in the transformation matrix $T$ to see what happens. Swap $A$ for the identity matrix to try a pure translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if one would like to stretch the image along the x-axis, one simply applies $A$ as a diagonal matrix with some stretching factor $k$. Create a stretching matrix with a factor $k$ along a diagonal direction with an affine transformation and apply to `mona`.\n",
    "\n",
    "Remember that `affine_warp` function takes a square transformation matrix $T$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "For any estimation task it is a good idea to have at least one test case where you know what the answer should be. In this exercise you should make such a test case for RANSAC. Start by generating random points, `pts`, and a random transformation. Then transform these points to create a `pts_tilde`. If you want to make it more realistic, add random noise to the points. You now have two sets of points related by a known affine transformation. In the following exercises you will try to estimate this transformation. As you know the correct answer it is easy to detect if you make a mistake. \t\n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def affine_test_case(N: int):\n",
    "    ...\n",
    "\n",
    "    return pts, pts_tilde, A_true, t_true\n",
    "```\n",
    "that generates a test case for estimating an affine transformation. The transformation should map `pts` to `pts_tilde`. Don't add any outliers now. Outputs `pts` and `pts_tilde` should be `2xN`-arrays. Also output the true transformation, so you know what to expect from your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import affine_test_case\n",
    "\n",
    "pts, pts_tilde, A_true, t_true = affine_test_case()\n",
    "\n",
    "print(f\"pts shape: {pts.shape}\")\n",
    "print(f\"pts_tilde shape: {pts_tilde.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4\n",
    "Make a minimal solver for the case of affine transformation estimation. In other words, make a function\n",
    "\n",
    "```python\n",
    "def estimate_affine(pts, pts_tilde):\n",
    "    ...\n",
    "    return A, t\n",
    "```\n",
    "that estimates an affine transformation mapping `pts` to `pts_tilde`, where `pts` and `pts_tilde` are `2xK` - arrays and $K$ is at least the number you found in Ex 3.1. Try your function on points from the test case in Ex 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import estimate_affine\n",
    "\n",
    "pts, pts_tilde, A_true, t_true = affine_test_case(N=10)\n",
    "A_est, t_est = estimate_affine(pts, pts_tilde)\n",
    "\n",
    "print(\"True A:\")\n",
    "print(A_true)\n",
    "print(\"Estimated A:\")\n",
    "print(A_est)\n",
    "print(\"True t:\")\n",
    "print(t_true)\n",
    "print(\"Estimated t:\")\n",
    "print(t_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.5\n",
    "Make a function\n",
    "\n",
    "```python\n",
    "def residual_lgths(A, t, pts, pts_tilde):\n",
    "    ...\n",
    "    return lgths\n",
    "```\n",
    "that computes the lengths of 2D residual vectors. the function should return an array with *N* values. Hint : Given a `2xN` matrix *M*, the column-wise sum of the squared elements can be computed as `np.sum(np.pow(M, 2), axis=0)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.6\n",
    "Modify your function `affine_test_case` to create a new function `affine_test_case_outlier` that takes parameters `outlier_rate`, `n_samples`, `image_height` and `image_width` and produces a percentage of outliers among the output points. For example, the outliers could be spread randomly over the image, or always shifted with a small translation.\n",
    "\n",
    "```python\n",
    "def affine_test_case_outlier(outlier_rate, n_samples, image_height, image_weight):\n",
    "    ...\n",
    "\n",
    "    return pts, pts_tilde, A_true, t_true, outlier_idxs\n",
    "```\n",
    "The function should also return the `outlier_idxs`, the indexes (as a boolean array) of the points that are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import affine_test_case_outlier\n",
    "\n",
    "outlier_rate = 0.1\n",
    "n_samples = 10\n",
    "image_height = 400\n",
    "image_width = 400\n",
    "pts, pts_tilde, A_true, t_true, outlier_idxs = affine_test_case_outlier(outlier_rate, \n",
    "                                                          n_samples=10, \n",
    "                                                          image_height=image_height, \n",
    "                                                          image_width=image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the difference between outliers and inliers. In the following plot, the green box marks the original \"image\", and the green rings the original, non-transformed points.\n",
    "\n",
    "Inlier points (generated with $A\\boldsymbol{x}+t$, green) will transform similarly. Outlier points (generated randomly, red) will not transform similarly to the inlier points. Ideally, we wish to estimate the transformation based on the inlier points only.\n",
    "\n",
    "Try varying the outlier ratio to better understand the difference between points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_affine_test_case_outlier\n",
    "\n",
    "f, ax = plot_affine_test_case_outlier(pts, pts_tilde, image_width, image_height, outlier_idxs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.7\n",
    "A naïve estimation of the transformation from `pts` to `pts_tilde` would be influenced by the outlier points. RANSAC is a method used to reject outliers and recover the underlying affine transformation from the inlier correspondences.\n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def ransace_fit_affine(pts: np.ndarray, pts_tilde: np.ndarray, threshold: float, n_iter: int = 10000, max_inliers: int = 0) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    ...\n",
    "    return A, t\n",
    "```\n",
    "that uses RANSAC to find an affine transformation between two sets of points. (Like before the transformation should map `pts` onto `pts_tilde`.) Test your function on test cases generated with your function `affine_test_case_outlier`. Try different outlier rates and RANSAC thresholds. Make sure that you get the right transformation and a reasonable number of outliers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import affine_test_case_outlier, ransac_fit_affine\n",
    "\n",
    "outlier_rate = 0.2\n",
    "thresh = 10\n",
    "image_height = 400\n",
    "image_width = 400\n",
    "pts, pts_tilde, A_true, t_true, outlier_idxs = affine_test_case_outlier(outlier_rate, \n",
    "                                                          n_samples=10, \n",
    "                                                          image_height=image_height, \n",
    "                                                          image_width=image_width)\n",
    "\n",
    "A_est, t_est = ransac_fit_affine(pts, pts_tilde, thresh=thresh)\n",
    "\n",
    "pts_est = A_est @ pts + t_est\n",
    "print(\"True A:\")\n",
    "print(A_true)\n",
    "print(\"Estimated A:\")\n",
    "print(A_est)\n",
    "print(\"True t:\")\n",
    "print(t_true)\n",
    "print(\"Estimated t:\")\n",
    "print(t_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain your observations with different values of threshold. Why do arbitrarily small values of threshold work in this case?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the estimated transformation. Inlier points (green) should be estimated correctly (green crosses), while the impact of the outlier points (red) should be disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_affine_test_case_outlier_with_est\n",
    "\n",
    "f, ax = plot_affine_test_case_outlier_with_est(pts, pts_tilde, pts_est, image_width, image_height, outlier_idxs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.8\n",
    "For this exercise, we will estimate the transformation matrix between two images. We will use SIFT to extract features from images in a source image at `source_path`, and a target image at `target_path`. However, to estimate the matrix (e.g. using RANSAC), we need point *correspondences*, that is *matched* points between the source and target. \n",
    "\n",
    "As such, we will use the supplied functions `extract_sift_features` and `match_descriptors` to find good points and match them between the images. Use these points to estimate the transformation using your `ransac_fit_affine` function.\n",
    "\n",
    "The image will then be warped using the supplied `affine_warp` function, which takes the source image, the affine transformation matrix, and the target image size as input.\n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def align_images(source: np.ndarray, target: np.ndarray, thresh: float = 10, plot: bool = True):\n",
    "    ...\n",
    "    return warped\n",
    "```\n",
    "where `thresh` is the threshold for the outliers in the `ransac_fit_affine` function, and `plot` is a boolean argument to plot the correspondences. You can use the function `plot_matches` in `visualization.py` for this (not compulsory).\n",
    "\n",
    "These functions use the OpenCV library for SIFT and RANSAC, and requires images to be in `uint8`(0-255) format. As such, please use the supplied `read_as_grayscale` function to ensure compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.9\n",
    "Align `vermeer_source.png` to `vermeer_target.png`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import align_images\n",
    "from supplied import read_as_grayscale\n",
    "\n",
    "source = read_as_grayscale('./data/vermeer_source.png')\n",
    "target = read_as_grayscale('./data/vermeer_target.png')\n",
    "\n",
    "warped  = align_images(source, target, thresh=0.1, plot=True)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(source, cmap='gray')\n",
    "ax[0].set_title('Source Image')\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title('Target Image')\n",
    "ax[2].imshow(warped, cmap='gray')\n",
    "ax[2].set_title('Aligned Image')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.10\n",
    "Try aligning the images `CT_1.jpg` and `CT_2.jpg`. Although SIFT is designed to be robust to changes in illumination and contrast, in practice, strong differences in intensity distributions can still affect keypoint detection and matching quality. Therefore, we will apply histogram equalization as a pre-processing step to improve contrast and make features more distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplied import read_as_grayscale\n",
    "import cv2 as cv\n",
    "\n",
    "source = read_as_grayscale('./data/CT_1.jpg')\n",
    "target = read_as_grayscale('./data/CT_2.jpg')\n",
    "\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "source = clahe.apply(source)\n",
    "target = clahe.apply(target)\n",
    "\n",
    "# Align the images using the function you implemented\n",
    "warped  = align_images(source, target, thresh=200)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(source, cmap='gray')\n",
    "ax[0].set_title(\"Source image\")\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title(\"Target image\")\n",
    "ax[2].imshow(warped, cmap='gray')\n",
    "ax[2].set_title(\"Warped image\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot target image in the warped image, using the same coordinates\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(target, cmap='gray')\n",
    "ax.imshow(warped, cmap='jet', alpha=0.2)\n",
    "ax.set_title(\"Target image warped to source image\")\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try varying the threshold for the inliers. What values are required to properly register the image? What are possible reasons for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.11\n",
    "Try aligning `tissue_fluorescent.tif` and `tissue_brightfield.tif`. \n",
    "\n",
    "Sometimes, some pre-processing is required. In the fluorescent image, the intensities are basically inverted, so you need to invert one of the images before computing descriptors. (Otherwise you will not get any good matches.) \n",
    "\n",
    "You may also find it helpful to do some pre-preprocessing of the image intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from supplied import read_as_grayscale\n",
    "\n",
    "source = read_as_grayscale('./data/tissue_brightfield.tif')\n",
    "target = read_as_grayscale('./data/tissue_fluorescent.tif')\n",
    "\n",
    "source = 255 - source\n",
    "\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "source = clahe.apply(source)\n",
    "target = clahe.apply(target)\n",
    "\n",
    "warped = align_images(source, target, thresh=100, plot=True)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(source, cmap='gray')\n",
    "ax[0].set_title(\"Source image\")\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title(\"Target image\")\n",
    "ax[2].imshow(warped, cmap='gray')\n",
    "ax[2].set_title(\"Warped image\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot target image in the warped image, using the same coordinates\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(target, cmap='gray')\n",
    "ax.imshow(warped, cmap='jet', alpha=0.2)\n",
    "ax.set_title(\"Target image warped to source image\")\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.12\n",
    "Sometimes it is beneficial to make a final correction of the RANSAC estimate, using all estimated inliers.\n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def ransac_fit_affine_ls(pts, pts_tilde, thresh, n_iter, max_inliers = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    ...\n",
    "    return A, t\n",
    "```\n",
    "by modifying your original `ransac_fit_affine` function to estimate an affine transformation mapping `pts` to `pts_tilde` in least squares sense, i.e., all inlier points in `pts` and `pts_tilde` are used to compute the transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.13\n",
    "**Make a function**\n",
    "```python\n",
    "def align_images_inlier_ls(\n",
    "        source: np.ndarray, \n",
    "        target: np.ndarray, \n",
    "        thresh: float = 10, \n",
    "        plot: bool=False) -> np.ndarray:\n",
    "    ...\n",
    "    return warped\n",
    "```\n",
    "that uses your new `ransac_fit_affine_ls`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.14\n",
    "Align `vermeer_source.png` to `vermeer_target.png` using `align_images_inliers_ls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import align_images_inlier_ls\n",
    "from supplied import read_as_grayscale\n",
    "\n",
    "source = read_as_grayscale('./data/vermeer_source.png')\n",
    "target = read_as_grayscale('./data/vermeer_target.png')\n",
    "\n",
    "warped  = align_images_inlier_ls(source, target, thresh=0.1, plot=True)\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(source, cmap='gray')\n",
    "ax[0].set_title('Source Image')\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title('Target Image')\n",
    "ax[2].imshow(warped, cmap='gray')\n",
    "ax[2].set_title('Aligned Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice an improvement?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warping\n",
    "### Exercise 3.15\n",
    "So far, you have used the OpenCV functions for warping the images, and we have not had to consider the mechanisms of actually reconstructing the image and its pixels given the transformation matrix.\n",
    "\n",
    "The algorithm for backwards warping to the original image can intuitively be written \n",
    "\n",
    "```\n",
    "for each pixel (x',y') in the transformed image:\n",
    "    1. Compute the inverse pixel coordinates (x, y)\n",
    "    2. Resample the source image intensities at (x, y)\n",
    "```\n",
    "\n",
    "It is fairly difficult to write a fast implementation for warping, but you will do so anyway. However, we will only use it for small images.\n",
    "\n",
    "You will first create a simple sampling function (step 2 in the algorithm) using neareast neighbours. \n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def sample_image_at(image, position):\n",
    "\n",
    "    return value\n",
    "```\n",
    "that gives you the pixel value at position. If the elements of position are not integers, select the value at the closest pixel. If it is outside the image, return 255 (i.e. white). \n",
    "\n",
    "Try the function on the transformed image `source_16x16.tif` to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import sample_image_at\n",
    "\n",
    "image = read_as_grayscale('./data/source_16x16.tif')\n",
    "value = sample_image_at(image, (4,5))\n",
    "print(value)\n",
    "\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.16\n",
    "Now, you will make a warping function that warps a 16 x 16 image according to the coordinate transfomation provided in the supplied function `transform_coordinates`\n",
    "\n",
    "**Make a function**\n",
    "```python\n",
    "def warp_16x16(source):\n",
    "\n",
    "    return warped\n",
    "```\n",
    "that warps source according to the function `transform_coordinates` and forms an output 16 x 16 image warped. \n",
    "\n",
    "`transform_coordinates` defines the coordinate transformation from target to source, that is, it takes a 2-vector `target_pos` as input, and maps it to the source image. \n",
    "\n",
    "In your function, loop over all target pixels and use the coordinate transformation along with your function `sample_image_at` to extract pixel values from the source image. Try the function on `source_16x16.tif`. You will know if you get it right.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import warp_16x16\n",
    "\n",
    "image = read_as_grayscale('./data/source_16x16.tif')\n",
    "warped = warp_16x16(image)\n",
    "\n",
    "plt.imshow(warped, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
